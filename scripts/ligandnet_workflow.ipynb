{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated LigandNet workflow\n",
    "\n",
    "## Author: Daniel Castaneda Mogollon\n",
    "### e-mail: <dann.dignus.discere@gmail.com>\n",
    "### Sirimulla Research Lab\n",
    "### Last modified: 08/03/2018\n",
    "\n",
    "\n",
    "### This workflow provides the user with the tools to generate a regression or classification model, in regards of predicting protein-ligand features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import glob\n",
    "from tqdm import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import  make_scorer, roc_auc_score, recall_score, accuracy_score, precision_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    print(\"What would you like to do? (please type only the number of your choice)\")\n",
    "    print(\"1. Classification\")\n",
    "    print(\"2. Regression\")\n",
    "    counter=0\n",
    "    answer=0\n",
    "    answer = input()\n",
    "    while (answer!=str(1) and answer!=str(2)) and counter<5:\n",
    "            answer = input(\"Please type ONLY a number between 1 and 2: \")\n",
    "            counter = counter+1\n",
    "            if counter == 5:\n",
    "                print(\"Too many attempts. Exiting program\")\n",
    "                sys.exit(1)\n",
    "    print(\"\\n\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining methods\n",
    "### Here we define a method that will execute the fingerprints by generating temporary files (don't worry, the temp files will be deleted). This method takes '.txt' input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TPATF_txt(main_path,temp_path,fingerprints_path,maya_path,pname):\n",
    "    f_run = \"perl \" + maya_path+'TopologicalPharmacophoreAtomTripletsFingerprints.pl'\n",
    "    command = f_run + \" -r \" + fingerprints_path+pname+\"_tpatf\"+\" --AtomTripletsSetSizeToUse FixedSize -v ValuesString -o \"+temp_path+pname+\"temp.sdf\"\n",
    "    os.system(command)\n",
    "    f_file = open(fingerprints_path+pname+\"_tpatf.csv\",\"r\").readlines()\n",
    "    for lines in f_file:\n",
    "        if 'Cmpd' in lines:\n",
    "            line = lines.split(';')[5].replace('\"','')\n",
    "            line = ','.join(line.split(' '))\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This method will skip those ligand SMILES that cannot be read, and it will delete the temporary files as well. It works only for '.txt' input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFingerprint_txt(pname,main_path,fingerprints_path,temp_path,maya_path):\n",
    "    active_file = open(main_path+pname+'.txt','r').readlines()\n",
    "    output = open(fingerprints_path+pname+'.csv','w')\n",
    "    for line in active_file:\n",
    "        try:\n",
    "            w = Chem.SDWriter(temp_path+pname+'temp.sdf')\n",
    "            smiles=line.split('\\t')[0]\n",
    "            try:\n",
    "                pic50 = line.split('\\t')[2].split('=')[1].rstrip('\\n')\n",
    "            except:\n",
    "                pass\n",
    "            mol=Chem.MolFromSmiles(smiles)\n",
    "            AllChem.Compute2DCoords(mol)\n",
    "            mol.SetProp(\"smiles\",smiles)\n",
    "            w.write(mol)\n",
    "            w.flush()\n",
    "            fingerprints = TPATF_txt(main_path,temp_path,fingerprints_path,maya_path,pname)\n",
    "            if main_path.endswith('actives/'):\n",
    "                output.write(smiles+','+pic50+','+fingerprints)\n",
    "            else:\n",
    "                output.write(smiles+','+fingerprints)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same method as TPATF but with '.sdf' file format instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TPATF_sdf(main_path,temp_path,fingerprints_path,maya_path,pname):\n",
    "    f_run = \"perl \" + maya_path+'TopologicalPharmacophoreAtomTripletsFingerprints.pl'\n",
    "    command = f_run + \" -r \" + fingerprints_path+pname+\"_tpatf\"+\" --AtomTripletsSetSizeToUse FixedSize -v ValuesString -o \"+temp_path+pname+\"temp.sdf\"\n",
    "    os.system(command)\n",
    "    f_file = open(fingerprints_path+pname+\"_tpatf.csv\",\"r\").readlines()\n",
    "    for lines in f_file:\n",
    "        if 'Cmpd' in lines:\n",
    "            line = lines.split(';')[5].replace('\"','')\n",
    "            line = ','.join(line.split(' '))\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same method as  generateFingerprint but with '.sdf' file format instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFingerprint_sdf(pname,main_path,fingerprints_path,temp_path,maya_path):\n",
    "    sdf_file = open(main_path+pname+'.sdf')\n",
    "    output2 = open(fingerprints_path+pname+'.csv','w')\n",
    "    w = open(temp_path+pname+'temp.sdf','w')\n",
    "    for line in sdf_file:\n",
    "        w.write(line)\n",
    "        if '$$$$' in line:\n",
    "            w.close()\n",
    "            try:\n",
    "                fingerprint = TPATF_sdf(main_path,temp_path,fingerprints_path,maya_path,pname)\n",
    "                output2.write(fingerprint)\n",
    "            except:\n",
    "               pass\n",
    "            w = open(temp_path+pname+'temp.sdf','w')\n",
    "    output2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the fingerprints for actives in decoys. The input should be either in '.sdf' format or '.txt' format. If it is '.txt', please make sure the file starts with SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fingerprints():\n",
    "    print(\"You have chosen a classification approach. Here, we will try to generate a model (of your choice) that will predict\") \n",
    "    print(\"if a ligand is an active or decoy, based on your input.\")\n",
    "    print('\\n')\n",
    "    print(\"For this, we need you to provide TWO files in a 'sdf' format. One file will contain the ACTIVES for a specific\") \n",
    "    print(\"protein, and the other will have the DECOYS.\")\n",
    "    print(\"\\n\")\n",
    "    print(\"In case you don't have the file for decoys, we recommend using http://dude.docking.org/generate or downloading\") \n",
    "    print(\"DecoyFinder through http://urvnutrigenomica-ctns.github.io/DecoyFinder/#Downloads_\\n\")\n",
    "    main_path = input(\"Please type the path where all of your files and folders are located (i.e /Users/Daniel/Desktop/ligand_net)\")\n",
    "    os.chdir(main_path)\n",
    "    if main_path[-1]!='/':                                          #Adding the last / to the path given\n",
    "        main_path = main_path+'/'\n",
    "    actives_path = main_path+'actives/'                             #Defining paths for everything\n",
    "    decoys_path = main_path+'decoys/'\n",
    "    temp_path = main_path+'temp/'\n",
    "    fingerprints_path = main_path+'fingerprints/'\n",
    "    maya_path = main_path+'mayachemtools/bin/'\n",
    "    maya_path_program = maya_path+'TopologicalPharmacophoreAtomTripletsFingerprints.pl'\n",
    "    f_run = \"perl \"+maya_path_program                               #fingerprint program\n",
    "    print(\"Getting fingerprints for actives . . .\")\n",
    "    #Getting the fingerprints of actives in .txt or .sdf format\n",
    "    for pname in tqdm(os.listdir(actives_path)):\n",
    "        if pname=='.DS_Store':                                      #Ignoring this file\n",
    "            continue\n",
    "        elif pname[-4:]=='.txt':\n",
    "            generateFingerprint_txt(pname[:-4],actives_path,fingerprints_path,temp_path,maya_path)\n",
    "            os.remove(temp_path+pname[:-4]+'temp.sdf')              #Removing temporary files\n",
    "            os.remove(fingerprints_path+pname[:-4]+'_tpatf.csv')    #Removing temporary files\n",
    "        elif pname[-4:]=='.sdf':\n",
    "            generateFingerprint_sdf(pname[:-4],actives_path,fingerprints_path,temp_path,maya_path)\n",
    "            os.remove(temp_path+pname[:-4]+'temp.sdf')              #Removing temporary files\n",
    "            os.remove(fingerprints_path+pname[:-4]+'_tpatf.csv')    #Removing temporary files\n",
    "            \n",
    "    print(\"Fingerprints for actives obtained.\")\n",
    "    print(\"Getting fingerprints for decoys . . .\")\n",
    "    #Getting the fingerprints of decoys in .txt format\n",
    "    for pname in tqdm(os.listdir(decoys_path)):\n",
    "        if pname=='.DS_Store':\n",
    "            continue\n",
    "        elif pname[-4:]=='.txt':\n",
    "            generateFingerprint_txt(pname[:-4],decoys_path,fingerprints_path,temp_path,maya_path)\n",
    "            os.remove(temp_path+pname[:-4]+'temp.sdf')\n",
    "            os.remove(fingerprints_path+pname[:-4]+'_tpatf.csv')\n",
    "        elif pname[-4:]=='.sdf':\n",
    "            generateFingerprint_sdf(pname[:-4],decoys_path,fingerprints_path,temp_path,maya_path)\n",
    "            os.remove(temp_path+pname[:-4]+'temp.sdf')              #Removing temporary files\n",
    "            os.remove(fingerprints_path+pname[:-4]+'_tpatf.csv')    #Removing temporary files\n",
    "            \n",
    "    print(\"Fingerprints for decoys obtained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the SVM method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-8-e8accfb7a068>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-e8accfb7a068>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    if 'Cmpd' in lines:\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def svm(fingerprints_path):\n",
    "    print('Reading actives fingerprints . . .')\n",
    "    for item in tqdm(os.listdir(fingerprints_path)):\n",
    "        active = open(fingerprints_path + item, 'r').readlines()\n",
    "        frame1 = []\n",
    "        for lines in active:\n",
    "        # print(lines)\n",
    "        if 'Cmpd' in lines:\n",
    "            line = lines.split(';')[5].rstrip('\"\\n').split(' ')\n",
    "            # print(len(line))\n",
    "            df = pd.DataFrame(np.array(line).reshape(1, len(line)))\n",
    "            df.astype(int)\n",
    "            frame1.append(df)\n",
    "    active_val = [1] * len(frame1)\n",
    "    c_list = [1,10,100]\n",
    "    gamma_list = [1,10,100]\n",
    "    classifier_sv = SVC(class_weight='balanced', kernel='linear', random_state=1, verbose=classifier_loglevel)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will be generating different models with a variety of Machine Learning approaches. It is up to you if you want to generate many or just one of your preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generation():\n",
    "    print(\"What would you like us to run for your model(s)?: \")\n",
    "    print(\"1. All the Machine Learning approaches we have (Random Forests,Support Vector Machine, Neural Networks, Extra Tree\")\n",
    "    print(\"Classifier)\")\n",
    "    print(\"2. Just one\")\n",
    "    all_or_one = input(\"Please answer with a number (1 or 2):\\n\")\n",
    "    counter = 0 \n",
    "    while (all_or_one!=str(1) and all_or_one!=str(2)):\n",
    "        counter = counter+1\n",
    "        all_or_one = input(\"Invalid option, please select 1 for an all model generation or 2 for a single one\")\n",
    "        if counter==5:\n",
    "            print(\"Too many attempts. Exiting program now.\")\n",
    "            sys.exit(1)\n",
    "    if all_or_one ==str(2):\n",
    "        print(\"You have selected only one ML approach. Which one would you like to run? (Please choose a number)\")\n",
    "        print(\"1. Support Vector Machine (SVM)\")\n",
    "        print(\"2. Random Forest (RF)\")\n",
    "        print(\"3. Extra Tree Classifier\")\n",
    "        print(\"4. Neural Networks (NN)\")\n",
    "        ml_model = input()\n",
    "        counter=0\n",
    "        while ml_model!=str(1) and ml_model!=str(2) and ml_model!=str(3) and ml_model!=str(4):\n",
    "            counter=counter+1\n",
    "            ml_model = input(\"Invalid option, please choose an integer number between 1 and 4:\")\n",
    "            if counter==5:\n",
    "                print(\"Too many attempts. Exiting program now.\")\n",
    "            sys.exit(1)\n",
    "        #if ml_model==str(1):\n",
    "           \n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main method (where we run everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would you like to do? (please type only the number of your choice)\n",
      "1. Classification\n",
      "2. Regression\n",
      "1\n",
      "\n",
      "\n",
      "You have chosen a classification approach. Here, we will try to generate a model (of your choice) that will predict\n",
      "if a ligand is an active or decoy, based on your input.\n",
      "\n",
      "\n",
      "For this, we need you to provide TWO files in a 'sdf' format. One file will contain the ACTIVES for a specific\n",
      "protein, and the other will have the DECOYS.\n",
      "\n",
      "\n",
      "In case you don't have the file for decoys, we recommend using http://dude.docking.org/generate or downloading\n",
      "DecoyFinder through http://urvnutrigenomica-ctns.github.io/DecoyFinder/#Downloads_\n",
      "\n",
      "Please type the path where all of your files and folders are located (i.e /Users/Daniel/Desktop/ligand_net)/Users/Danniel/Desktop/testing_ligandnet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting fingerprints for actives . . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:51<00:00, 17.07s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprints for actives obtained.\n",
      "Getting fingerprints for decoys . . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:50<00:00, 96.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprints for decoys obtained.\n",
      "What would you like us to run for your model(s)?: \n",
      "1. All the Machine Learning approaches we have (Random Forests,Support Vector Machine, Neural Networks, Extra Tree\n",
      "Classifier)\n",
      "2. Just one\n",
      "Please answer with a number (1 or 2):\n",
      "2\n",
      "You have selected only one ML approach. Which one would you like to run? (Please choose a number)\n",
      "1. Support Vector Machine (SVM)\n",
      "2. Random Forest (RF)\n",
      "3. Extra Tree Classifier\n",
      "4. Neural Networks (NN)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    answer = start()\n",
    "    if answer == str(1):\n",
    "        fingerprints()\n",
    "        model_generation()\n",
    "    elif answer == str(2):\n",
    "        print('Regression is being built at the moment...')\n",
    "    \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
